{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Dark Art of Coding:\n",
    "## Introduction to Python\n",
    "Gathering data from the web\n",
    "\n",
    "<img src='../images/dark_art_logo.600px.png' width='300' style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, students should expect to:\n",
    "\n",
    "* Use and understand the basics of the `urllib` module\n",
    "* Use and understand the basics of the `beautiful soup` library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCP\n",
    "\n",
    "TCP is a protocol that is used to send data across a network\n",
    "\n",
    "* It relies upon some builtin mechanisms to help increase reliability\n",
    "* TCP creates connections between two devices (it is referred to as a connection-oriented protocol)\n",
    "* It uses checks to ensure that all data has been correctly received, if not, it can request that missing data be resent\n",
    "* TCP organizes packets in order\n",
    "* Between the reliability checks and the organization/ordering of packets, it is very effective for the sending files (like web pages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Port numbers\n",
    "\n",
    "The TCP protocol incorporates the use of port numbers:\n",
    "\n",
    "* Port numbers are used by computers to ensure that traffic coming to a given computer gets funneled to the correct application\n",
    "* Multiple ports allow multiple applications on the same computer to talk without interfering with each other\n",
    "* Typically certain applications have default TCP port numbers that are used to send higher-level protocols\n",
    "\n",
    "Task | Port\n",
    ":----|:----\n",
    "Telnet | 23\n",
    "SSH | 22\n",
    "HTTP | 80\n",
    "HTTPS | 443\n",
    "SMTP (E-mail) | 25\n",
    "DNS (Domain Name) | 53\n",
    "FTP (File Transfer) | 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTP (Hyper Text Transfer Protocol)\n",
    "\n",
    "HTTP is a common protocol that may be sent using TCP.\n",
    "\n",
    "* HTTP is the standard Protocol for most applications on the internet\n",
    "* Invented to retrieve HTML, images, Documents, etc.\n",
    "* Basic concept:\n",
    "    * Make a connection\n",
    "    * Request a document\n",
    "    * Retrieve the document\n",
    "    * Close the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTTP uses Uniform Resource Locators (URL) to identify device addresses. A URL address has several components:\n",
    "\n",
    "* The URL indicates the protocol, generally HTTP (but it could be others)\n",
    "* It lists the server that hosts the document\n",
    "* The name and path to the document\n",
    "\n",
    "http://  | http://www.example.com/ | index.html\n",
    ":--------|:-------------|:----------------\n",
    "Protocol | Host         | Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# HTTP\n",
    "\n",
    "* Browser attempts to connect to `http://www.example.com`\n",
    "* Issues a request for a document such as `index.html`\n",
    "* The server sends the html document\n",
    "* Browser renders html\n",
    "* Closes connection when done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standing up a local HTTP server\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python lets you stand up your own HTTP server.\n",
    "This lesson is designed for use in connectionless environments, where you may not have access to the Internet.\n",
    "\n",
    "In those cases, we start this lesson by standing up our own server and using Python to interact with webpages on that server. The behaviors and code will all be the same >>> the only thing that changes is the URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the following on the commandline. It will run an HTTP server on your local computer... in the folder where you execute the Python command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ cd path/to/this/lesson_directory/12_internet/\n",
    "$ python -m http.server 9999\n",
    "```\n",
    "\n",
    "|Command|Purpose|\n",
    "|:--|:---|\n",
    "|`python` | calls the Python interpreter directly|\n",
    "|`-m` | requests that the interpreter load the `http.server` module, which automatically starts a basic HTTP server.|\n",
    "|`9999` | designates which port to use for your server|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open your browser and surf to:\n",
    "\n",
    "```bash\n",
    "localhost:9999\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see something looks like this:\n",
    "    \n",
    "<img src='./http_server_dir_list.png' width='300' style=\"float:center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTTP requests in Python using urllib\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we have to import the request module from urllib\n",
    "\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# urllib allows us to open web pages just like opening files.\n",
    "# The following command creates an http.client.HTTPResponse object that\n",
    "#     gives us access to a number of attributes and behaviors\n",
    "#     related to the data retrieved\n",
    "\n",
    "file = urllib.request.urlopen('http://localhost:9999/annabel_lee.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annabel Lee\n",
      "Edgar Allen Poe, 1809 - 1849\n",
      "\n",
      "It was many and many a year ago,\n",
      "In a kingdom by the sea,\n",
      "That a maiden there lived whom you may know\n",
      "By the name of Annabel Lee;\n",
      "And this maiden she lived with no other thought\n",
      "Than to love and be loved by me.\n",
      "\n",
      "I was a child and she was a child,\n",
      "In this kingdom by the sea:\n",
      "But we loved with a love that was more than love--\n",
      "I and my Annabel Lee;\n",
      "With a love that the winged seraphs of heaven\n",
      "Coveted her and me.\n",
      "\n",
      "And this was the reason that, long ago,\n",
      "In this kingdom by the sea,\n",
      "A wind blew out of a cloud, chilling\n",
      "My beautiful Annabel Lee;\n",
      "So that her highborn kinsman came\n",
      "And bore her away from me,\n",
      "To shut her up in a sepulchre\n",
      "In this kingdom by the sea.\n",
      "\n",
      "The angels, not half so happy in heaven,\n",
      "Went envying her and me--\n",
      "Yes!--that was the reason (as all men know,\n",
      "In this kingdom by the sea)\n",
      "That the wind came out of the cloud by night,\n",
      "Chilling and killing my Annabel Lee.\n",
      "\n",
      "But our love it was stronger by far than the love\n",
      "Of those who were older than we--\n",
      "Of many far wiser than we--\n",
      "And neither the angels in heaven above,\n",
      "Nor the demons down under the sea,\n",
      "Can ever dissever my soul from the soul\n",
      "Of the beautiful Annabel Lee:\n",
      "\n",
      "For the moon never beams, without bringing me dreams\n",
      "Of the beautiful Annabel Lee;\n",
      "And the stars never rise, but I feel the bright eyes\n",
      "Of the beautiful Annabel Lee;\n",
      "And so, all the night-tide, I lie down by the side\n",
      "Of my darling--my darling--my life and my bride,\n",
      "In her sepulchre there by the sea,\n",
      "In her tomb by the sounding sea.\n"
     ]
    }
   ],
   "source": [
    "# A common technique is to use a for loop to cycle through every\n",
    "# line and print out the data one line at a time\n",
    "# In this case, the data is read in as bytes\n",
    "\n",
    "for line in file:\n",
    "    # We convert each line from bytes to strings using the\n",
    "    #     .decode() attribute.\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Much like other files we have looked at, we can \n",
    "# read and evaluate the text in web-based text files, like\n",
    "# like counting words\n",
    "\n",
    "import pprint\n",
    "import urllib.request\n",
    "file = urllib.request.urlopen('http://localhost:9999/annabel_lee.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = {}\n",
    "\n",
    "for line in file:\n",
    "    \n",
    "    # Again, we take the line and use .decode() to convert\n",
    "    #     the data to a string\n",
    "    #     Then we strip the newline\n",
    "    #     Then we split it on spaces\n",
    "    words = line.decode().strip().split()\n",
    "    \n",
    "    # We cycle through the words one at a time\n",
    "    for word in words:\n",
    "        \n",
    "        # If a key for the word already exists .get() grabs the value otherwise it automatically returns 0\n",
    "        count[word] = count.get(word, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'(as': 1,\n",
      " '-': 1,\n",
      " '1809': 1,\n",
      " '1849': 1,\n",
      " 'A': 1,\n",
      " 'Allen': 1,\n",
      " 'And': 6,\n",
      " 'Annabel': 8,\n",
      " 'But': 2,\n",
      " 'By': 1,\n",
      " 'Can': 1,\n",
      " 'Chilling': 1,\n",
      " 'Coveted': 1,\n",
      " 'Edgar': 1,\n",
      " 'For': 1,\n",
      " 'I': 4,\n",
      " 'In': 7,\n",
      " 'It': 1,\n",
      " 'Lee': 1,\n",
      " 'Lee.': 1,\n",
      " 'Lee:': 1,\n",
      " 'Lee;': 5,\n",
      " 'My': 1,\n",
      " 'Nor': 1,\n",
      " 'Of': 6,\n",
      " 'Poe,': 1,\n",
      " 'So': 1,\n",
      " 'Than': 1,\n",
      " 'That': 2,\n",
      " 'The': 1,\n",
      " 'To': 1,\n",
      " 'Went': 1,\n",
      " 'With': 1,\n",
      " 'Yes!--that': 1,\n",
      " 'a': 9,\n",
      " 'above,': 1,\n",
      " 'ago,': 2,\n",
      " 'all': 2,\n",
      " 'and': 8,\n",
      " 'angels': 1,\n",
      " 'angels,': 1,\n",
      " 'away': 1,\n",
      " 'be': 1,\n",
      " 'beams,': 1,\n",
      " 'beautiful': 4,\n",
      " 'blew': 1,\n",
      " 'bore': 1,\n",
      " 'bride,': 1,\n",
      " 'bright': 1,\n",
      " 'bringing': 1,\n",
      " 'but': 1,\n",
      " 'by': 11,\n",
      " 'came': 2,\n",
      " 'child': 1,\n",
      " 'child,': 1,\n",
      " 'chilling': 1,\n",
      " 'cloud': 1,\n",
      " 'cloud,': 1,\n",
      " 'darling--my': 2,\n",
      " 'demons': 1,\n",
      " 'dissever': 1,\n",
      " 'down': 2,\n",
      " 'dreams': 1,\n",
      " 'envying': 1,\n",
      " 'ever': 1,\n",
      " 'eyes': 1,\n",
      " 'far': 2,\n",
      " 'feel': 1,\n",
      " 'from': 2,\n",
      " 'half': 1,\n",
      " 'happy': 1,\n",
      " 'heaven': 2,\n",
      " 'heaven,': 1,\n",
      " 'her': 7,\n",
      " 'highborn': 1,\n",
      " 'in': 3,\n",
      " 'it': 1,\n",
      " 'killing': 1,\n",
      " 'kingdom': 5,\n",
      " 'kinsman': 1,\n",
      " 'know': 1,\n",
      " 'know,': 1,\n",
      " 'lie': 1,\n",
      " 'life': 1,\n",
      " 'lived': 2,\n",
      " 'long': 1,\n",
      " 'love': 5,\n",
      " 'love--': 1,\n",
      " 'loved': 2,\n",
      " 'maiden': 2,\n",
      " 'many': 3,\n",
      " 'may': 1,\n",
      " 'me': 1,\n",
      " 'me,': 1,\n",
      " 'me--': 1,\n",
      " 'me.': 2,\n",
      " 'men': 1,\n",
      " 'moon': 1,\n",
      " 'more': 1,\n",
      " 'my': 5,\n",
      " 'name': 1,\n",
      " 'neither': 1,\n",
      " 'never': 2,\n",
      " 'night,': 1,\n",
      " 'night-tide,': 1,\n",
      " 'no': 1,\n",
      " 'not': 1,\n",
      " 'of': 4,\n",
      " 'older': 1,\n",
      " 'other': 1,\n",
      " 'our': 1,\n",
      " 'out': 2,\n",
      " 'reason': 2,\n",
      " 'rise,': 1,\n",
      " 'sea)': 1,\n",
      " 'sea,': 4,\n",
      " 'sea.': 2,\n",
      " 'sea:': 1,\n",
      " 'sepulchre': 2,\n",
      " 'seraphs': 1,\n",
      " 'she': 2,\n",
      " 'shut': 1,\n",
      " 'side': 1,\n",
      " 'so': 1,\n",
      " 'so,': 1,\n",
      " 'soul': 2,\n",
      " 'sounding': 1,\n",
      " 'stars': 1,\n",
      " 'stronger': 1,\n",
      " 'than': 4,\n",
      " 'that': 3,\n",
      " 'that,': 1,\n",
      " 'the': 26,\n",
      " 'there': 2,\n",
      " 'this': 6,\n",
      " 'those': 1,\n",
      " 'thought': 1,\n",
      " 'to': 1,\n",
      " 'tomb': 1,\n",
      " 'under': 1,\n",
      " 'up': 1,\n",
      " 'was': 7,\n",
      " 'we': 1,\n",
      " 'we--': 2,\n",
      " 'were': 1,\n",
      " 'who': 1,\n",
      " 'whom': 1,\n",
      " 'wind': 2,\n",
      " 'winged': 1,\n",
      " 'wiser': 1,\n",
      " 'with': 2,\n",
      " 'without': 1,\n",
      " 'year': 1,\n",
      " 'you': 1}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unicode and Python text\n",
    "\n",
    "* Internally, within Python 3+, all Python strings are Unicode\n",
    "* When we talk to a network we usually have to encode and decode our data (generally to `utf-8`)\n",
    "* When we recieve data we typically recieve it as a `bytes` object which we then pass through a `.decode()` method to get a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'> b'   In her tomb by the sounding sea.'\n"
     ]
    }
   ],
   "source": [
    "# Poor man debugging...\n",
    "# I find this to be one of the most useful lines of code to a \n",
    "#     new Pythonista\n",
    "\n",
    "print(type(line), line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'   In her tomb by the sounding sea.'\n",
      "   In her tomb by the sounding sea.\n"
     ]
    }
   ],
   "source": [
    "# Let us look at the difference between outputting:\n",
    "#     a bytes object vs.\n",
    "#     a string\n",
    "\n",
    "print(line)\n",
    "print(line.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading web pages\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><head><title>Jabberwocky</title></head><body bgcolor=\"#FFFFFF\">\n",
      "<center><h1>JABBERWOCKY</h1>\n",
      "\n",
      "<h2>Lewis Carroll</h2>\n",
      "\n",
      "(from <cite>Through the Looking-Glass and What Alice Found There</cite>,\n",
      "1872)\n",
      "\n",
      "<p>\n",
      "<font size=\"+2\">\n",
      "`Twas brillig, and the slithy toves<br>\n",
      "&nbsp;&nbsp;Did gyre and gimble in the wabe:<br>\n",
      "All mimsy were the borogoves,<br>\n",
      "&nbsp;&nbsp;And the mome raths outgrabe.<p>\n",
      "</center>\n",
      "\n",
      "<img src=\"./pics/jabberwocky.jpg\" align=\"right\" border=0 width=291\n",
      "height=432>\n",
      "\n",
      "<p><br>\n",
      "\n",
      "\"Beware the Jabberwock, my son!<br>\n",
      "&nbsp;&nbsp;The jaws that bite, the claws that catch!<br>\n",
      "Beware the Jubjub bird, and shun<br>\n",
      "&nbsp;&nbsp;The frumious Bandersnatch!\"<br>\n",
      "\n",
      "<p>\n",
      "\n",
      "He took his vorpal sword in hand:<br>\n",
      "&nbsp;&nbsp;Long time the manxome foe he sought --<br>\n",
      "So rested he by the Tumtum tree,<br>\n",
      "&nbsp;&nbsp;And stood awhile in thought.<br>\n",
      "\n",
      "<p>\n",
      "\n",
      "And, as in uffish thought he stood,<br>\n",
      "&nbsp;&nbsp;The Jabberwock, with eyes of flame,<br>\n",
      "Came whiffling through the tulgey wood,<br>\n",
      "&nbsp;&nbsp;And burbled as it came!<br>\n",
      "\n",
      "<p>\n",
      "\n",
      "One, two!  One, two!  And through and through<br>\n",
      "&nbsp;&nbsp;The vorpal blade went snicker-snack!<br>\n",
      "He left it dead, and with its head<br>\n",
      "&nbsp;&nbsp;He went galumphing back.<br>\n",
      "\n",
      "<p>\n",
      "\n",
      "\"And, has thou slain the Jabberwock?<br>\n",
      "&nbsp;&nbsp;Come to my arms, my beamish boy!<br>\n",
      "O frabjous day!  Callooh!  Callay!'<br>\n",
      "&nbsp;&nbsp;He chortled in his joy.<br>\n",
      "\n",
      "<br clear=\"all\"><center><br>\n",
      "\n",
      "`Twas brillig, and the slithy toves<br>\n",
      "&nbsp;&nbsp;Did gyre and gimble in the wabe;<br>\n",
      "All mimsy were the borogoves,<br>\n",
      "&nbsp;&nbsp;And the mome raths outgrabe.\n",
      "\n",
      "<p>\n",
      "\n",
      "</center>\n",
      "</font>\n",
      "<br clear=\"all\">\n",
      "<p>\n",
      "<a\n",
      "href=\"mailto:dshaw@jabberwocky.com\"><address>dshaw@jabberwocky.com</address></a>\n",
      "<hr>\n",
      "<a href=\"/carroll/jabber/\">Return to Glorious Nonsense</a><br>\n",
      "<a href=\"/carroll/\">Return to Lewis Carroll</a><br>\n",
      "<a href=\"/\">Return to Jabberwocky</a>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Our earlier examples were fairly straightforward, since we \n",
    "#     retrieved text files. Most of the web is not \n",
    "#     straight text files, it is composed of \n",
    "#     Hyper Text Markup Language (HTML)\n",
    "\n",
    "# We request a page using urllib.request.urlopen()\n",
    "\n",
    "page = urllib.request.urlopen('http://localhost:9999/jabberwocky.html')\n",
    "\n",
    "for line in page:\n",
    "    print(line.decode().strip())\n",
    "    \n",
    "# source:\n",
    "# http://www.jabberwocky.com/carroll/jabber/jabberwocky.html    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful soup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is possible to use `urllib` to read data from the web, a third party library, `Beautiful Soup` is commonly used instead to supplement urllib. `Beautiful Soup`:\n",
    "\n",
    "* Makes reading and parsing web pages a lot easier\n",
    "* Allows you to extract tags of only certain types\n",
    "* You can find certain tags based on their relationship in the tag heirarchy\n",
    "* Getting hyperlinks becomes a whole lot easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the command line\n",
    "\n",
    "To install Beautiful Soup, if not already installed, you can run this on the command line:\n",
    "\n",
    "*`conda install beautifulsoup4`*\n",
    "\n",
    "## In a Python file/interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the html text from the HTTPResponse object\n",
    "# Notice the read() method >>>\n",
    "\n",
    "htmlText = urllib.request.urlopen('http://localhost:9999/jabberwocky.html').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use bs4 to create a soup object from our html text\n",
    "# Provide a argument to identify which type of parser to\n",
    "#     use, in this case, an html parser\n",
    "\n",
    "soup = BeautifulSoup(htmlText, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The soup object allows you to retrieve specific types of tags, in this\n",
    "#     anchor tags (identified using an 'a'). Anchor tags are used for links.\n",
    "\n",
    "tags = soup('a') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mailto:dshaw@jabberwocky.com\n",
      "/carroll/jabber/\n",
      "/carroll/\n",
      "/\n"
     ]
    }
   ],
   "source": [
    "# Let's cycle through the tags and get the 'href' data portion. this is the data that contains the link itself\n",
    "\n",
    "for tag in tags:\n",
    "    print(tag.get('href', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using documentation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the documentation for a third party library.\n",
    "\n",
    "The documentation for Beautiful Soup has a number of nice attributes that can get you started fairly quickly, so let's use the documentation to enhance our knowledge of the subject.\n",
    "\n",
    "[Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping\n",
    "---\n",
    "\n",
    "## What is web scraping?\n",
    "\n",
    "Web scraping is a technique used to retrieve data from the web OR from similar networks (intranets, etc).\n",
    "\n",
    "* Web scrapers simulate the behavior of a browser\n",
    "* They look at the data from specific site(s)\n",
    "* They extract specific information you need from it\n",
    "* Typically this is done over and over again across multiple sites\n",
    "\n",
    "## Why web scrape?\n",
    "\n",
    "* Get data from a sites that don't provide mechanisms to export the data\n",
    "* Collect information on sites to build a search engine database\n",
    "* Monitor sites for changes\n",
    "* Collect social network data\n",
    "    * who is connected to or communicates with who?\n",
    "    * What is being said"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
