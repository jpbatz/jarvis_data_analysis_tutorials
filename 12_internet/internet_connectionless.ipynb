{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Dark Art of Coding:\n",
    "## Introduction to Python\n",
    "Gathering data from the web\n",
    "\n",
    "<img src='../images/dark_art_logo.600px.png' width='300' style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, students should expect to:\n",
    "\n",
    "* Use and understand the basics of the urllib module\n",
    "* Use and understand the basics of the beautiful soup library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCP\n",
    "\n",
    "TCP is a protocol that is used to send data across a network\n",
    "\n",
    "* It relies upon some builtin mechanisms to help increase reliability\n",
    "* TCP creates connections between two devices (connection oriented protocol)\n",
    "* It uses checks to ensure that all data has been sent, if not can request that missing data be resent\n",
    "* TCP organizes packets in order\n",
    "* Between the reliability checks and the organization/ordering of packets, it work very well for sending files (like web pages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Port numbers\n",
    "\n",
    "The TCP protocol incorporates the use of port numbers:\n",
    "\n",
    "* Port numbers are used by computers to ensure that traffic coming to a given computer gets funneled to the correct application\n",
    "* Multiple ports allow multiple applications on the same computer to talk without interfering with each other\n",
    "* Typically certain applications have default TCP port numbers that are used to send higher-level protocols\n",
    "\n",
    "Task | Port\n",
    ":----|:----\n",
    "Telnet | 23\n",
    "SSH | 22\n",
    "HTTP | 80\n",
    "HTTPS | 443\n",
    "SMTP (E-mail) | 25\n",
    "DNS (Domain Name) | 53\n",
    "FTP (File Transfer) | 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTP (Hyper Text Transfer Protocol)\n",
    "\n",
    "HTTP is a common protocol that may be sent using TCP.\n",
    "\n",
    "* HTTP is the standard Protocol for most applications on the internet\n",
    "* Invented to retrieve HTML, images, Documents, etc.\n",
    "* Basic concept:\n",
    "    * Make a connection\n",
    "    * Request a document\n",
    "    * Retrieve the document\n",
    "    * Close the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical Uniform Resource Locator (URL) address has several components:\n",
    "\n",
    "* The URL indicates the protocol, generally HTTP (but it could be others)\n",
    "* It lists the server that hosts the document\n",
    "* The name and path to the document\n",
    "\n",
    "http://  | www.py4e.com | /lessons/network\n",
    ":--------|:-------------|:----------------\n",
    "Protocol | Host         | Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# HTTP\n",
    "\n",
    "* Browser attempts to connect to `http://www.example.com`\n",
    "* Issues a request for a document such as `index.html`\n",
    "* The server sends the html document\n",
    "* Browser renders html\n",
    "* Closes connection when done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standing up a local HTTP server\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python lets you stand up your own HTTP server.\n",
    "This lesson is designed for use in connectionless environments, where you may not have access to the Internet.\n",
    "\n",
    "In those cases, we start this lesson by standing up our own server and using Python to interact with webpages on that server. The behaviors and code will all be the same >>> the only thing that changes is the URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the following on the commandline. It will run an HTTP server on your local computer... in the folder where you execute the Python command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ cd path/to/the/lesson 11/folder/11\n",
    "$ python -m http.server 8000\n",
    "```\n",
    "\n",
    "|||\n",
    "|:--|:---|\n",
    "|`python` | calls the Python interpreter directly|\n",
    "|`-m` | requests that the interpreter load the `http.server` module, which automatically starts a basic HTTP server.|\n",
    "|`8000` | is the port that your server is running on.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open your browser and surf to:\n",
    "\n",
    "```bash\n",
    "localhost:8000\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see something looks like this:\n",
    "    \n",
    "<img src='./http_server_dir_list.png' width='300' style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTTP requests in Python using urllib\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unknown url type: 'annabel_lee.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9d228b14d2af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     related to the data retrieved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'annabel_lee.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# A common technique is to use a for loop to cycle through every\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chalmerlowe/miniconda3/envs/jarvis/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chalmerlowe/miniconda3/envs/jarvis/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m# accept a URL or a Request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullurl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chalmerlowe/miniconda3/envs/jarvis/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, url, data, headers, origin_req_host, unverifiable, method)\u001b[0m\n\u001b[1;32m    327\u001b[0m                  \u001b[0morigin_req_host\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munverifiable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                  method=None):\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munredirected_hdrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chalmerlowe/miniconda3/envs/jarvis/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mfull_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfragment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeleter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chalmerlowe/miniconda3/envs/jarvis/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown url type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplithost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unknown url type: 'annabel_lee.txt'"
     ]
    }
   ],
   "source": [
    "# First we have to import the request module from urllib\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "# urllib allows us to open web pages just like opening files.\n",
    "# The following command creates an http.client.HTTPResponse object that\n",
    "#     gives us access to a number of attributes and behaviors\n",
    "#     related to the data retrieved\n",
    "\n",
    "file = urllib.request.urlopen('annabel_lee.txt')\n",
    "\n",
    "# A common technique is to use a for loop to cycle through every\n",
    "# line and print out the data one line at a time\n",
    "# In this case, the data is read in as bytes\n",
    "\n",
    "for line in file:\n",
    "    # We convert each line from bytes to strings using the\n",
    "    #     .decode() attribute.\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Much like other files we have looked at, we can \n",
    "# read and evaluate the text in web-based text files, like\n",
    "# like counting words\n",
    "\n",
    "import pprint\n",
    "import urllib.request\n",
    "\n",
    "url = 'http://localhost:8000/annabel_lee.txt'\n",
    "file = urllib.request.urlopen(url)\n",
    "\n",
    "count = {}\n",
    "\n",
    "for line in file:\n",
    "    \n",
    "    # Again, we take the line and use .decode() to convert\n",
    "    #     the data to a string\n",
    "    #     Then we strip the newline\n",
    "    #     Then we split it on spaces\n",
    "    words = line.decode().strip().split()\n",
    "    \n",
    "    # We cycle through the words one at a time\n",
    "    for word in words:\n",
    "        \n",
    "        # If a key for the word already exists .get() grabs the value otherwise it automatically returns 0\n",
    "        count[word] = count.get(word, 0) + 1\n",
    "\n",
    "pprint.pprint(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unicode and Python text\n",
    "\n",
    "* Internally, within Python 3+, all Python strings are Unicode\n",
    "* When we talk to a network we usually have to encode and decode our data (generally to `utf-8`)\n",
    "* When we recieve data we typically recieve it as a `bytes` object which we then pass through a `.decode()` method to get a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Poor man debugging...\n",
    "# This is one of the most important lines of code to any new Pythonista\n",
    "\n",
    "print(type(line), line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let us look at the difference between outputting:\n",
    "#     a bytes object vs.\n",
    "#     a string\n",
    "\n",
    "print(line)\n",
    "print(line.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading web pages\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our earlier examples were fairly straightforward, since we \n",
    "#     retrieved text files. Most of the web is not \n",
    "#     straight text files, it is composed of \n",
    "#     Hyper Text Markup Language (HTML)\n",
    "\n",
    "# We request a page using urllib.request.urlopen()\n",
    "\n",
    "page = urllib.request.urlopen('http://localhost:8000/jabberwocky.html')\n",
    "\n",
    "text = page.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our earlier examples were fairly straightforward, since we \n",
    "#     retrieved text files. Most of the web is not \n",
    "#     straight text files, it is composed of \n",
    "#     Hyper Text Markup Language (HTML)\n",
    "\n",
    "# We request a page using urllib.request.urlopen()\n",
    "\n",
    "page = urllib.request.urlopen('http://localhost:8000/jabberwocky.html')\n",
    "\n",
    "for line in page:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful soup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is possible to use `urllib` to read data from the web, a third party library, `Beautiful Soup` is commonly used instead to supplement urllib. `Beautiful Soup`:\n",
    "\n",
    "* Makes reading and parsing web pages a lot easier\n",
    "* Allows you to extract tags of only certain types\n",
    "* You can find certain tags based on their relationship in the tag heirarchy\n",
    "* Getting hyperlinks becomes a whole lot easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the command line\n",
    "\n",
    "To install Beautiful Soup, you can run this on the command line:\n",
    "\n",
    "*`conda install beautifulsoup4`*\n",
    "\n",
    "## In a Python file/interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "# Get the html text from the HTTPResponse object\n",
    "# Notice the read() method >>>\n",
    "\n",
    "htmlText = urllib.request.urlopen('http://localhost:8000/jabberwocky.html').read()\n",
    "\n",
    "# Use bs4 to create a soup object from our html text\n",
    "# Provide a argument to identify which type of parser to\n",
    "#     use, in this case, an html parser\n",
    "\n",
    "soup = BeautifulSoup(htmlText, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The soup object allows you to retrieve specific types of tags, in this\n",
    "#     anchor tags (identified using an 'a'). Anchor tags are used for links.\n",
    "\n",
    "tags = soup('a') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dshaw@jabberwocky.com\n"
     ]
    }
   ],
   "source": [
    "# Let's cycle through the tags and get the 'href' attribute.\n",
    "# This is the data that contains the link itself\n",
    "\n",
    "import re\n",
    "pattern = re.compile(r'mailto:(.*)')\n",
    "\n",
    "\n",
    "for tag in tags:\n",
    "    attr = tag.get('href', None)\n",
    "    # print('attr', attr)\n",
    "    matchObj = pattern.search(attr)\n",
    "    if matchObj:\n",
    "        print(matchObj.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scrapy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using documentation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the documentation for a third party library.\n",
    "\n",
    "The documentation for Beautiful Soup has a number of nice attributes that can get you started fairly quickly, so let's use the documentation to enhance our knowledge of the subject.\n",
    "\n",
    "[Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping\n",
    "---\n",
    "\n",
    "## What is web scraping?\n",
    "\n",
    "Web scraping is a technique used to retrieve data from the web OR from similar networks (intranets, etc).\n",
    "\n",
    "* Web scrapers simulate the behavior of a browser\n",
    "* They look at the data from specific site(s)\n",
    "* They extract specific information you need from it\n",
    "* Typically this is done over and over again across multiple sites\n",
    "\n",
    "## Why web scrape?\n",
    "\n",
    "* Get data from a sites that don't provide mechanisms to export the data\n",
    "* Collect information on sites to build a search engine database\n",
    "* Monitor sites for changes\n",
    "* Collect social network data\n",
    "    * who is connected to or communicates with who?\n",
    "    * What is being said"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source:\n",
    "# http://www.jabberwocky.com/carroll/jabber/jabberwocky.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
